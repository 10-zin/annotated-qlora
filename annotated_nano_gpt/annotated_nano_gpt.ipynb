{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.normalization.LayerNorm"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(torch.nn, \"LayerNorm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1779, -0.1302,  0.9696],\n",
      "         [-0.3571, -0.5792, -0.2485],\n",
      "         [ 0.8429, -2.2337, -0.1311]],\n",
      "\n",
      "        [[ 0.4909, -1.9780, -0.0793],\n",
      "         [-0.2605, -0.7634,  1.1383],\n",
      "         [-0.7953, -0.5048, -1.6523]],\n",
      "\n",
      "        [[-0.0388,  1.5982, -0.5791],\n",
      "         [-0.4683,  1.3370, -0.4797],\n",
      "         [ 2.3081,  1.6312,  0.3573]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7516, -0.6616,  1.4132],\n",
       "         [ 0.2748, -1.3385,  1.0637],\n",
       "         [ 1.0517, -1.3447,  0.2930]],\n",
       "\n",
       "        [[ 0.9598, -1.3794,  0.4196],\n",
       "         [-0.3712, -0.9962,  1.3674],\n",
       "         [ 0.3876,  0.9840, -1.3716]],\n",
       "\n",
       "        [[-0.3949,  1.3735, -0.9786],\n",
       "         [-0.7004,  1.4142, -0.7138],\n",
       "         [ 1.0830,  0.2460, -1.3291]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, sentence_length, embedding_dim = 3, 3, 3\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "print(embedding)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "layer_norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rope_cache(\n",
    "    seq_len: int, n_elem: int, device = None, base: int = 10000, condense_ratio: int = 1\n",
    ") :\n",
    "    \"\"\"Enhanced Transformer with Rotary Position Embedding.\n",
    "\n",
    "    Derived from: https://github.com/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/\n",
    "    transformers/rope/__init__.py. MIT License:\n",
    "    https://github.com/labmlai/annotated_deep_learning_paper_implementations/blob/master/license.\n",
    "    \"\"\"\n",
    "    # $\\Theta = {\\theta_i = 10000^{\\frac{2(i-1)}{d}}, i \\in [1, 2, ..., \\frac{d}{2}]}$\n",
    "\n",
    "    theta = 1.0 / (base ** (torch.arange(0, n_elem, 2, device=device).float() / n_elem))\n",
    "\n",
    "    # Create position indexes `[0, 1, ..., seq_len - 1]`\n",
    "    seq_idx = torch.arange(seq_len, device=device) / condense_ratio\n",
    "\n",
    "    # Calculate the product of position index and $\\theta_i$\n",
    "    idx_theta = torch.outer(seq_idx, theta).repeat(1, 2)\n",
    "\n",
    "    return torch.cos(idx_theta), torch.sin(idx_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "         [ 0.5403,  0.9504,  0.9950,  0.9995,  0.9999,  1.0000,  1.0000,  1.0000,\n",
       "           0.5403,  0.9504,  0.9950,  0.9995,  0.9999,  1.0000,  1.0000,  1.0000],\n",
       "         [-0.4161,  0.8066,  0.9801,  0.9980,  0.9998,  1.0000,  1.0000,  1.0000,\n",
       "          -0.4161,  0.8066,  0.9801,  0.9980,  0.9998,  1.0000,  1.0000,  1.0000],\n",
       "         [-0.9900,  0.5828,  0.9553,  0.9955,  0.9996,  1.0000,  1.0000,  1.0000,\n",
       "          -0.9900,  0.5828,  0.9553,  0.9955,  0.9996,  1.0000,  1.0000,  1.0000],\n",
       "         [-0.6536,  0.3011,  0.9211,  0.9920,  0.9992,  0.9999,  1.0000,  1.0000,\n",
       "          -0.6536,  0.3011,  0.9211,  0.9920,  0.9992,  0.9999,  1.0000,  1.0000],\n",
       "         [ 0.2837, -0.0103,  0.8776,  0.9875,  0.9988,  0.9999,  1.0000,  1.0000,\n",
       "           0.2837, -0.0103,  0.8776,  0.9875,  0.9988,  0.9999,  1.0000,  1.0000],\n",
       "         [ 0.9602, -0.3208,  0.8253,  0.9821,  0.9982,  0.9998,  1.0000,  1.0000,\n",
       "           0.9602, -0.3208,  0.8253,  0.9821,  0.9982,  0.9998,  1.0000,  1.0000],\n",
       "         [ 0.7539, -0.5994,  0.7648,  0.9756,  0.9976,  0.9998,  1.0000,  1.0000,\n",
       "           0.7539, -0.5994,  0.7648,  0.9756,  0.9976,  0.9998,  1.0000,  1.0000],\n",
       "         [-0.1455, -0.8186,  0.6967,  0.9682,  0.9968,  0.9997,  1.0000,  1.0000,\n",
       "          -0.1455, -0.8186,  0.6967,  0.9682,  0.9968,  0.9997,  1.0000,  1.0000],\n",
       "         [-0.9111, -0.9566,  0.6216,  0.9598,  0.9960,  0.9996,  1.0000,  1.0000,\n",
       "          -0.9111, -0.9566,  0.6216,  0.9598,  0.9960,  0.9996,  1.0000,  1.0000]]),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.4147e-01,  3.1098e-01,  9.9833e-02,  3.1618e-02,  9.9998e-03,\n",
       "           3.1623e-03,  1.0000e-03,  3.1623e-04,  8.4147e-01,  3.1098e-01,\n",
       "           9.9833e-02,  3.1618e-02,  9.9998e-03,  3.1623e-03,  1.0000e-03,\n",
       "           3.1623e-04],\n",
       "         [ 9.0930e-01,  5.9113e-01,  1.9867e-01,  6.3203e-02,  1.9999e-02,\n",
       "           6.3245e-03,  2.0000e-03,  6.3246e-04,  9.0930e-01,  5.9113e-01,\n",
       "           1.9867e-01,  6.3203e-02,  1.9999e-02,  6.3245e-03,  2.0000e-03,\n",
       "           6.3246e-04],\n",
       "         [ 1.4112e-01,  8.1265e-01,  2.9552e-01,  9.4726e-02,  2.9995e-02,\n",
       "           9.4867e-03,  3.0000e-03,  9.4868e-04,  1.4112e-01,  8.1265e-01,\n",
       "           2.9552e-01,  9.4726e-02,  2.9995e-02,  9.4867e-03,  3.0000e-03,\n",
       "           9.4868e-04],\n",
       "         [-7.5680e-01,  9.5358e-01,  3.8942e-01,  1.2615e-01,  3.9989e-02,\n",
       "           1.2649e-02,  4.0000e-03,  1.2649e-03, -7.5680e-01,  9.5358e-01,\n",
       "           3.8942e-01,  1.2615e-01,  3.9989e-02,  1.2649e-02,  4.0000e-03,\n",
       "           1.2649e-03],\n",
       "         [-9.5892e-01,  9.9995e-01,  4.7943e-01,  1.5746e-01,  4.9979e-02,\n",
       "           1.5811e-02,  5.0000e-03,  1.5811e-03, -9.5892e-01,  9.9995e-01,\n",
       "           4.7943e-01,  1.5746e-01,  4.9979e-02,  1.5811e-02,  5.0000e-03,\n",
       "           1.5811e-03],\n",
       "         [-2.7942e-01,  9.4715e-01,  5.6464e-01,  1.8860e-01,  5.9964e-02,\n",
       "           1.8973e-02,  6.0000e-03,  1.8974e-03, -2.7942e-01,  9.4715e-01,\n",
       "           5.6464e-01,  1.8860e-01,  5.9964e-02,  1.8973e-02,  6.0000e-03,\n",
       "           1.8974e-03],\n",
       "         [ 6.5699e-01,  8.0042e-01,  6.4422e-01,  2.1956e-01,  6.9943e-02,\n",
       "           2.2134e-02,  6.9999e-03,  2.2136e-03,  6.5699e-01,  8.0042e-01,\n",
       "           6.4422e-01,  2.1956e-01,  6.9943e-02,  2.2134e-02,  6.9999e-03,\n",
       "           2.2136e-03],\n",
       "         [ 9.8936e-01,  5.7432e-01,  7.1736e-01,  2.5029e-01,  7.9915e-02,\n",
       "           2.5296e-02,  7.9999e-03,  2.5298e-03,  9.8936e-01,  5.7432e-01,\n",
       "           7.1736e-01,  2.5029e-01,  7.9915e-02,  2.5296e-02,  7.9999e-03,\n",
       "           2.5298e-03],\n",
       "         [ 4.1212e-01,  2.9126e-01,  7.8333e-01,  2.8078e-01,  8.9879e-02,\n",
       "           2.8457e-02,  8.9999e-03,  2.8460e-03,  4.1212e-01,  2.9126e-01,\n",
       "           7.8333e-01,  2.8078e-01,  8.9879e-02,  2.8457e-02,  8.9999e-03,\n",
       "           2.8460e-03]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope_pct=0.25\n",
    "n_embed=512\n",
    "n_head=8\n",
    "head_size = n_embed//n_head\n",
    "n_elem = int(rope_pct*head_size)\n",
    "print(n_elem)\n",
    "build_rope_cache(10, n_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((512,), eps=1.0, elementwise_affine=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = torch.nn.modules.normalization.LayerNorm\n",
    "layer_norm(512, eps=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(5, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_layer = nn.Linear(8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = inp_layer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0198,  0.3577, -0.5207, -0.1539,  0.3153, -0.6795,  0.2200,\n",
       "           0.5134],\n",
       "         [ 0.4865, -0.1810, -0.2653, -0.4134, -0.7792, -0.2879, -0.3637,\n",
       "          -0.5716],\n",
       "         [-0.3169, -0.3722,  0.0184,  1.5840,  0.2090,  0.6374, -0.7977,\n",
       "           1.5537],\n",
       "         [-0.0475, -0.9240, -0.2025,  1.4259,  1.9119, -0.3163,  0.4386,\n",
       "          -0.0115],\n",
       "         [ 1.8534,  0.8006, -0.3712, -0.4632,  0.1588,  1.1213, -0.4442,\n",
       "           1.0335],\n",
       "         [ 0.3740, -0.6893, -0.5329, -0.0106,  1.8452, -0.4108,  1.1671,\n",
       "           0.5873],\n",
       "         [ 0.0759,  1.8401, -0.6289,  0.3394, -1.5147, -1.5296, -0.6283,\n",
       "           0.1567],\n",
       "         [-0.9164, -0.3853,  0.0749, -0.0648,  0.9237,  0.7397, -1.6918,\n",
       "          -0.3539],\n",
       "         [ 0.9429,  2.0696,  0.2259, -1.0724, -0.0069, -0.4512, -0.3075,\n",
       "           1.2850],\n",
       "         [ 1.7650,  0.5711,  0.5113,  0.6858,  1.2570,  0.9052,  1.8211,\n",
       "          -0.7861]],\n",
       "\n",
       "        [[ 0.4796, -0.2595, -0.4435, -0.2692, -2.4653,  0.9393,  1.9443,\n",
       "           0.2285],\n",
       "         [ 0.7023,  1.8220, -1.6878, -1.2104,  1.7056, -0.4901,  0.5171,\n",
       "           1.2729],\n",
       "         [-0.1043,  0.9498,  1.5686,  1.4561,  0.9898, -0.4849,  2.4422,\n",
       "          -1.4957],\n",
       "         [ 0.2702, -0.3154,  0.3497,  1.3245, -0.0120, -1.6961, -1.0714,\n",
       "           0.8563],\n",
       "         [-0.1486,  1.9227, -0.0903, -0.7328, -0.2938,  1.0316, -0.2344,\n",
       "          -0.1263],\n",
       "         [ 0.2100,  0.1946,  0.8816, -0.0386, -0.3147,  0.1585, -0.0646,\n",
       "           0.9616],\n",
       "         [ 2.1097,  0.0156,  0.2614,  1.4877, -0.2980, -0.2090, -0.2008,\n",
       "          -0.1881],\n",
       "         [ 0.7905,  0.8774,  1.3821, -1.0113,  1.3355, -0.9429, -0.0195,\n",
       "          -0.2692],\n",
       "         [ 0.5777,  0.8347,  0.4503, -0.4750, -0.1728,  1.6606, -1.5675,\n",
       "           0.6606],\n",
       "         [-1.3576, -1.2638,  1.1001, -0.3950, -0.2609, -1.0006,  1.3371,\n",
       "           1.1562]],\n",
       "\n",
       "        [[-1.2239, -1.3629,  0.0207,  0.8017,  0.6999,  0.5263,  0.1867,\n",
       "          -2.3883],\n",
       "         [-0.0793, -0.1423,  0.9780, -0.5503, -1.6803, -1.0408, -2.5827,\n",
       "           0.0743],\n",
       "         [-2.1942, -0.2819, -1.4259, -1.3922,  0.4913, -0.2070,  1.4811,\n",
       "          -1.7674],\n",
       "         [-0.6565, -2.4048, -0.3892,  1.2877,  0.4160, -1.2285,  1.8431,\n",
       "          -0.3678],\n",
       "         [-1.2285,  1.2197,  0.7520,  1.8458,  0.1222, -0.1604, -0.0038,\n",
       "           0.4194],\n",
       "         [-1.6105,  0.5621,  0.1295, -0.3704,  0.3365, -1.4441,  0.1864,\n",
       "           0.2103],\n",
       "         [-0.2825,  0.3590,  1.2124, -0.3936,  1.8969, -0.1167, -0.0992,\n",
       "           1.0777],\n",
       "         [ 1.7288,  1.6921, -2.3598, -0.6138,  0.3299,  0.2018,  1.3446,\n",
       "          -1.3376],\n",
       "         [ 1.0626, -1.0979, -0.2647,  0.8470,  0.5108, -0.2591, -1.1509,\n",
       "           0.3915],\n",
       "         [ 0.1916, -0.6686, -0.2648, -0.3076, -0.4413, -0.5098, -2.1098,\n",
       "           0.4123]],\n",
       "\n",
       "        [[-0.4049,  2.4654,  0.9421, -0.3631, -0.8648, -0.3275, -0.9043,\n",
       "           0.8306],\n",
       "         [ 0.8293, -1.3267, -0.0100,  1.6848,  0.3530, -0.0815, -2.1045,\n",
       "           1.0642],\n",
       "         [ 1.8002, -0.6086,  0.7584, -0.0637,  0.2939,  0.2375, -1.6034,\n",
       "           0.5730],\n",
       "         [-0.5392,  0.0250,  0.5934, -0.5923, -0.5860,  1.6408,  0.0440,\n",
       "           0.9778],\n",
       "         [-0.3211, -1.3898,  0.0475, -1.0743, -0.4777,  0.8017, -2.3790,\n",
       "           0.2398],\n",
       "         [ 0.8574,  1.1446,  1.9178,  1.6410,  0.4044, -1.0862, -0.8766,\n",
       "           0.8860],\n",
       "         [ 1.5558,  0.0308, -1.1406, -0.1320,  1.9834, -0.5186,  0.7492,\n",
       "          -0.0075],\n",
       "         [ 0.4298, -0.0490, -0.6353, -0.4194,  1.8833, -0.9527,  0.4174,\n",
       "           2.3993],\n",
       "         [-0.1782, -2.7747,  0.0825, -0.3732,  0.2047, -1.5507, -1.1374,\n",
       "          -2.0433],\n",
       "         [-0.6095, -1.1244, -1.9808, -0.2332,  1.2685, -0.8094,  0.7297,\n",
       "           0.4385]],\n",
       "\n",
       "        [[ 0.7165, -1.2583,  1.2647,  0.4298, -0.1897,  0.8695, -0.1043,\n",
       "          -0.3849],\n",
       "         [-2.4572,  0.0718,  0.2225,  0.5535,  2.1298, -2.1124,  0.8711,\n",
       "          -0.5810],\n",
       "         [-0.1613,  0.3459,  1.1486, -1.8734,  0.7352, -0.9184,  1.7563,\n",
       "          -0.0723],\n",
       "         [-0.3670, -0.8035,  0.8971, -2.5219,  1.0102, -1.4610,  1.5435,\n",
       "          -0.8903],\n",
       "         [-0.1408, -0.3345, -0.7586, -0.6681,  0.7987,  0.1322, -2.0280,\n",
       "           0.7146],\n",
       "         [ 0.4657, -0.1094, -0.6826,  2.6773, -1.0783,  0.0619, -0.9454,\n",
       "          -0.1455],\n",
       "         [-0.0751, -1.7814,  0.1234, -0.3533,  0.3775,  0.9259, -1.2608,\n",
       "           1.2605],\n",
       "         [ 1.3682, -0.6843,  1.6667,  1.1597, -0.3906,  1.0217,  0.5331,\n",
       "          -1.3136],\n",
       "         [-0.2321,  0.1546,  1.8394,  0.3493, -0.8989,  0.3414, -0.0302,\n",
       "          -0.1180],\n",
       "         [-0.5271,  3.4374, -0.1876,  0.1332,  0.6202,  1.6884,  0.1818,\n",
       "           0.1529]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2382,  1.2814,  0.4812,  0.6993,  0.3840],\n",
       "         [ 0.3007, -0.3421, -0.5420,  0.2970, -0.5170],\n",
       "         [-0.9252, -0.0696,  0.0864,  0.4234,  0.1360],\n",
       "         [-0.8374, -0.0107, -0.3267,  0.2979,  0.6358],\n",
       "         [-0.3415, -0.1580, -0.0230,  0.0275, -0.6359],\n",
       "         [-0.7547,  0.4643, -0.1063,  0.5789, -0.0361],\n",
       "         [ 0.1354,  0.7427, -0.7805,  0.0535, -0.6395],\n",
       "         [-0.0532, -0.1849,  0.8555,  0.8299,  0.8211],\n",
       "         [-0.5045,  0.7879,  0.3762,  0.4318, -1.0083],\n",
       "         [-0.5817, -0.4732, -0.8947, -1.3382,  0.0570]],\n",
       "\n",
       "        [[ 0.3030, -0.2322, -1.3049, -0.9431, -1.1370],\n",
       "         [-0.3908,  1.7777,  0.4137,  0.5385, -0.1016],\n",
       "         [-0.7657, -0.0157, -0.9643, -1.5109,  0.3757],\n",
       "         [-0.8375, -0.1582, -0.4734,  1.0624, -0.6310],\n",
       "         [ 0.1777,  0.5551,  0.3654, -0.4976,  0.1714],\n",
       "         [-0.6529, -0.1334,  0.1244,  0.3624, -0.7437],\n",
       "         [-0.4757, -1.0268, -1.3639, -0.4294, -0.6449],\n",
       "         [-0.6276,  0.0293,  0.4315,  0.6240, -0.5962],\n",
       "         [-0.1889, -0.3834,  0.7114,  0.2077, -0.1434],\n",
       "         [-0.8522,  0.3171,  0.1854,  1.0719, -0.9863]],\n",
       "\n",
       "        [[ 0.3776, -0.6687, -0.4176, -0.3130,  1.3070],\n",
       "         [ 0.1167, -0.7267,  0.2050,  1.4741, -1.0848],\n",
       "         [ 0.8826,  1.1766,  0.0587,  0.0677,  0.9827],\n",
       "         [-0.4894, -0.1755, -1.2391,  0.3727, -0.0738],\n",
       "         [-0.8328,  0.5162, -0.0656, -0.4355,  0.5356],\n",
       "         [-0.3316,  1.0992,  0.3851,  0.8450, -0.0207],\n",
       "         [-1.1636,  0.4161,  1.0976,  0.9359, -0.0961],\n",
       "         [ 0.7714,  0.7571, -1.2874, -1.2076,  0.2260],\n",
       "         [-0.4810, -0.7248, -0.4226,  0.8721, -0.2826],\n",
       "         [ 0.0107, -0.3974,  0.1796,  1.4707, -0.5086]],\n",
       "\n",
       "        [[-0.3817,  0.7169,  0.5334,  0.1264, -0.5628],\n",
       "         [-0.7989, -0.9597, -0.2367,  1.1532, -0.1932],\n",
       "         [-0.5554, -1.1516,  0.0442,  0.9509, -0.8634],\n",
       "         [-0.3125, -0.0577,  0.6136,  0.1017, -0.3061],\n",
       "         [ 0.2543, -0.7927,  0.8288,  1.6037, -0.2684],\n",
       "         [-1.3851, -0.3700, -0.1851,  0.2422, -0.6627],\n",
       "         [-0.4210,  0.3675, -0.4934,  0.2854, -0.0188],\n",
       "         [-1.2430,  1.1362,  0.5380,  1.4760, -0.6320],\n",
       "         [ 0.4791, -1.2416, -0.5260,  1.5911, -0.1568],\n",
       "         [-0.1284,  0.9906, -0.1864,  1.0338,  0.2970]],\n",
       "\n",
       "        [[-0.3926, -1.3924, -0.3510,  0.0341, -0.4326],\n",
       "         [-0.6941,  1.3722,  0.3938,  0.8096,  0.9810],\n",
       "         [-0.4543,  0.5678,  0.3676,  0.5103, -0.9098],\n",
       "         [-0.0734,  0.3022,  0.3820,  1.1599, -0.8638],\n",
       "         [-0.1025,  0.1803,  0.8457,  1.5359,  0.1351],\n",
       "         [-0.1633, -0.6480, -1.4274, -0.5419,  0.2494],\n",
       "         [-0.5026, -0.6056,  0.7174,  1.4747, -0.3274],\n",
       "         [-0.3376, -1.7815, -1.0683, -1.0217, -0.3208],\n",
       "         [-0.4641, -0.7008, -0.0776, -0.1726, -0.5537],\n",
       "         [-0.2007,  1.2879,  0.6184, -1.3721,  1.0397]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Parameter containing:\n",
      "tensor([[-0.0385,  0.0064, -0.2588, -0.1811, -0.2059,  0.0646, -0.0766, -0.3341],\n",
      "        [-0.3284,  0.3485, -0.3106, -0.1192,  0.1465, -0.1673,  0.1596,  0.2262],\n",
      "        [-0.3073,  0.0724,  0.1839, -0.3316,  0.2906,  0.1636, -0.2439,  0.2170],\n",
      "        [-0.1010, -0.3238,  0.0081, -0.3178,  0.1464, -0.3321, -0.3470,  0.2954],\n",
      "        [-0.3328,  0.1112, -0.2162,  0.2379,  0.3264,  0.2564, -0.0960, -0.2863]],\n",
      "       requires_grad=True)\n",
      "bias Parameter containing:\n",
      "tensor([-0.1837,  0.0024, -0.1589,  0.2194, -0.1644], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in inp_layer.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
